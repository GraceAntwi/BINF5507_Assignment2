{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "\n",
    "#load the heart_disease_uci dataset\n",
    "heart_data = pd.read_csv('heart_disease_uci(1).csv')\n",
    "\n",
    "#check data types and basic statistics\n",
    "# heart_data.head()\n",
    "# heart_data.info()\n",
    "# heart_data.describe()\n",
    "\n",
    "\n",
    "#encode categorical columns\n",
    "categorical_cols = heart_data.select_dtypes(include=['object']).columns \n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_array = encoder.fit_transform(heart_data[categorical_cols])\n",
    "encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "df = pd.concat([heart_data.drop(categorical_cols, axis=1,), encoded_df], axis=1)\n",
    "print(df)\n",
    "\n",
    "#remove NaNs\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "\n",
    "#define features and targert\n",
    "X = df.drop(columns=['chol']) #features\n",
    "y = df['chol'] #targets\n",
    "\n",
    "\n",
    "#split data into train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # scale the features(X)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#list to store evaluation metrics\n",
    "alphas = np.logspace(0, 1, 10)\n",
    "l1_ratios = np.linspace(0, 1, 10)\n",
    "\n",
    "r2_scores = []\n",
    "rmse_scores = []\n",
    "\n",
    "# #ElasticNet for linear regression\n",
    "for alpha in alphas:\n",
    "    for l1_ratio in l1_ratios:\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state = 42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        #Evaluate\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        r2_scores.append([alpha, l1_ratio, r2])\n",
    "        rmse_scores.append([alpha, l1_ratio, rmse])\n",
    "print(r2_scores)\n",
    "print(rmse_scores)\n",
    "\n",
    "#convert r2 and rmse to Dataframes\n",
    "r2_df = pd.DataFrame(r2_scores, columns=['alpha', 'l1_ratio', 'R2'])\n",
    "print(r2_df)\n",
    "rmse_df = pd.DataFrame(rmse_scores, columns=['alpha', 'l1_ratio', 'RMSE'])\n",
    "print(rmse_df)\n",
    "\n",
    "#Pivot for heatmap\n",
    "r2_pivot = r2_df.pivot(index=\"alpha\",columns=\"l1_ratio\", values=\"R2\")\n",
    "rmse_pivot = rmse_df.pivot(index=\"alpha\", columns=\"l1_ratio\", values=\"RMSE\")\n",
    "\n",
    "# #plot R2 heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(r2_pivot, annot=True, fmt='.4f', cmap='viridis', cbar_kws={'label': 'R2'})\n",
    "plt.title('R2 for ElasticNet')\n",
    "plt.xlabel('L1_Ratio')\n",
    "plt.xlabel('Alpha')\n",
    "plt.show()\n",
    "\n",
    "# #plot RMSE heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(rmse_pivot, annot=True, fmt='.4f', cmap='mako', cbar_kws={'label': 'RMSE'} )\n",
    "plt.title('RMSE for ElasticNet')\n",
    "plt.xlabel('L1_Ratio')\n",
    "plt.xlabel('Alpha')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# #find top-perfoming configuration \n",
    "top_r2 = r2_df.loc[r2_df['R2'].idxmax()]\n",
    "print(top_r2)\n",
    "top_rmse = rmse_df.loc[rmse_df['RMSE'].idxmin()]\n",
    "print(top_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---Classification models---\n",
    "\n",
    "#Define target for classification; target = num\n",
    "X = df.drop(columns=['num']) \n",
    "y = df['num'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "#split data into test data and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # scale the features(X)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Hyperparameter grid for Logistic Regression\n",
    "logreg_param_grid = [\n",
    "    {'penalty': ['l1'], 'solver': ['liblinear', 'saga'] },\n",
    "    {'penalty': ['l2'], 'solver': ['liblinear', 'saga', 'lbfgs']},\n",
    "\n",
    "]\n",
    "    \n",
    "#Logistic regression with GridSearchCV\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg_grid = GridSearchCV(logreg, logreg_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "\n",
    "#best logistic regression model\n",
    "best_logreg = logreg_grid.best_estimator_\n",
    "print(f\"Best Logistic Regression params: {logreg_grid.best_params_}\")\n",
    "\n",
    "# #Predictions\n",
    "y_pred_logreg = best_logreg.predict(X_test)\n",
    "y_prob_logreg = best_logreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# #Logistic regression evaluation\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "logreg_f1 = f1_score(y_test, y_pred_logreg, average='weighted')\n",
    "logreg_auroc = roc_auc_score(y_test, y_prob_logreg, multi_class='ovr')\n",
    "\n",
    "print('Accuracy:', logreg_accuracy)\n",
    "print('F1 Score:', logreg_f1 )\n",
    "print('AUROC:', logreg_auroc)\n",
    "\n",
    "\n",
    "#k-Nearest neighbors(k-NN)\n",
    "\n",
    "#Hyperparameter grid for k-NN\n",
    "knn_param_grid = {\n",
    "    'n_neighbors':[1, 5, 10, 15, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "#K-NN with GridSearchCV\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn, knn_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "#Best K-NN model\n",
    "best_knn = knn_grid.best_estimator_\n",
    "print(f\"Best k-NN params: {knn_grid.best_params_}\")\n",
    "\n",
    "#Predictions\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "y_prob_knn = best_knn.predict_proba(X_test)\n",
    "\n",
    "#K-NN evaluation\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_f1 = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "knn_auroc = roc_auc_score(y_test, y_prob_knn, multi_class='ovr')\n",
    "\n",
    "print('Knn Accuracy:', knn_accuracy)\n",
    "print('Knn F1 Score:', knn_f1)\n",
    "print('Knn AUROC:', knn_auroc)\n",
    "\n",
    "#AUROC & AUPRC CURVES\n",
    "precision_logreg, recall_logreg, _ = precision_recall_curve(y_test, y_prob_logreg)\n",
    "pr_auc_logreg = auc(recall_logreg, precision_logreg)\n",
    "\n",
    "#Precision-recall curve for K-NN\n",
    "precision_knn, recall_knn, _ = precision_curve(y_test, y_prob_knn)\n",
    "pr_auc_knn = auc(recall_knn, precision_knn)\n",
    "\n",
    "#Plot AUROC Curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "fpr_logreg_, tpr_logreg, _ = roc_curve(y_test, y_prob_knn)\n",
    "fpr_knn, tpr_knn, _ = roc_curvey(y_test, y_prob_knn)\n",
    "\n",
    "plt.plot(fpr_logreg, tpr_logreg, label='AUPRC')\n",
    "plt.plot(fpr_knn, tpr_knn, label=\"AUROC\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUROC Curve')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "#plot AUPRC curves\n",
    "plt.plot(recall_logreg, precision_logreg, label='AUPRC')\n",
    "plt.plot(recall_knn, precsision_knn, label=\"k-NN AUROC\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('AUPRC Curve')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
